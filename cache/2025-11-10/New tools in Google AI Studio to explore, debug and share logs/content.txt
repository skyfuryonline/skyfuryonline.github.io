Breadcrumb
Technology
Developers
New tools in Google AI Studio to explore, debug and share logs
Oct 30, 2025
·
3 min read
Read AI-generated summary
General summary
Google AI Studio now has logs and datasets to help you check AI quality and build confidently. Enable logging in the AI Studio dashboard to track GenerateContent API calls without changing code. Export logs as datasets to refine prompts track performance and share feedback with Google.
Summaries were generated by Google AI. Generative AI is experimental.
Bullet points
Google AI Studio's new tools help you explore, debug, and share logs to improve AI app quality.
Enable logging in AI Studio to automatically track GenerateContent API calls without changing code.
Export logs as datasets to test, refine prompts, and track performance using the Gemini Batch API.
Share datasets with Google to provide feedback and help improve Google's AI models and services.
These tools streamline debugging, improve observability, and help you build AI apps with confidence.
Summaries were generated by Google AI. Generative AI is experimental.
Basic explainer
Google made some new tools for AI Studio. These tools help people see how well their AI is working and fix any problems. It's like checking if your AI is giving good answers. People can also share info to help Google make their AI even better.
Summaries were generated by Google AI. Generative AI is experimental.
Explore other styles:
General summary
Bullet points
Basic explainer
Share
Twitter
Facebook
LinkedIn
Mail
Copy link
Launching logs and datasets, new tools in Google AI Studio designed to give you a clear view of how your AI app is performing and enhance your app development flow.
S
Seth Odoom
Product Manager, Google AI Studio
S
Sara Wiltberger
Senior Product Manager, Google Labs
Share
Twitter
Facebook
LinkedIn
Mail
Copy link
We’re introducing a new
logs and datasets
feature in Google AI Studio, to help developers assess the quality of AI outputs and build with more confidence.
A key challenge in developing AI-first applications is getting consistent, high-quality results — especially as you iterate and grow. These new tools help to improve observability and streamline your debugging workflows, giving you quick and simple insights into how your application is working for both you and your end users. They also lay the groundwork for a broader set of evaluation capabilities.
The new logging and datasets tool in Google AI Studio
Easily track everything, no new code required
Setup is simple: All you need to do is click “Enable logging” in the AI Studio dashboard to make API calls for your
billing-enabled project
visible in the dashboard. This will automatically track all supported GenerateContent API calls from that billing-enabled Cloud project — whether they’re successful or not. This creates a user interaction history for your AI systems without requiring code changes.
You can get logging at no monetary cost in all regions where the Gemini API is available. Use the table to view response codes and filter by status to quickly identify logs to debug. You can also dive into specific log attributes, like inputs, outputs, and API tool usage, to trace a user complaint back to the exact model interaction. This makes debugging, testing, and refining your app much more effective.
Sorry, your browser doesn't support embedded videos, but don't worry, you can
download it
and watch it with your favorite video player!
Click "Enable Logging" and get interaction history for all API calls from there on
Turn insights into product excellence
Every user interaction is a chance to improve your product and the model’s ability to deliver better responses. You can export your logs as specific datasets (in CSV or JSONL format) for testing and offline evaluation. By identifying examples in your logs where quality and performance dipped (or excelled), you can build a reliable and reproducible baseline of expected results.
You can use these datasets for prompt refinement, performance tracking and more. For example, you can use the Gemini Batch API to run batch evaluations using datasets built up over time, see the
Datasets Cookbook
for an example. This allows you to test the changes to your Gemini model selection or application logic before you deploy them to users.
You also have the option to share specific datasets with Google to provide feedback on end-to-end model behavior for your specific use case. Shared datasets will be used to improve and develop Google products and services, including improving and training our models.
Sorry, your browser doesn't support embedded videos, but don't worry, you can
download it
and watch it with your favorite video player!
Create datasets and filter by status, share feedback with Google and export as needed
Get started today
Start prototyping and building AI-first apps in the
Google AI Studio Build
mode. Once you enable logging at the project level, you can monitor your application from its first prototype all the way to production. Read more about the tools in
our docs
and join our
Developer Forum
to share feedback.
POSTED IN:
Developers
AI
Related stories
Company announcements
Google is investing in Oklahoma’s workforce and talent pipeline.
Nov 07, 2025
Developers
Introducing the File Search Tool in Gemini API
By
Ivan Solovyev
&
Animesh Chatterji
Nov 06, 2025
Learning & Education
AI and learning: A new chapter for students and educators
By
Ben Gomes
&
Lila Ibrahim
Nov 06, 2025
Search
Google Finance adds AI features for research, earnings and more
By
Robert Dunnette
Nov 06, 2025
Developers
Improving Structured Outputs in the Gemini API
By
Gemini API Team
Nov 05, 2025
AI
The latest AI news we announced in October
By
Keyword Team
Nov 04, 2025
.
Jump to position 1
Jump to position 2
Jump to position 3
Jump to position 4
Jump to position 5
Jump to position 6